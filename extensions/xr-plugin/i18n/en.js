module.exports = {
    title: 'XR',
    description: 'XR related nodes and components',
    xrui: 'XRUI',
    node: {
        convert_main_camera_to_xr_hmd: 'Convert Camera To XR HMD',
        convert_2dui_to_3dui: 'Convert 2DUI To XRUI',
        xr_agent: 'XR Agent',
        xr_hmd: 'XR HMD',
        ray_interactor: 'Ray Interactor',
        direct_interactor: 'Direct Interactor',
        locomotion_checker: 'Locomotion Checker',
        teleportable: 'Teleportable',
        simple_interactable: 'Simple Interactable',
        grab_interactable: 'Grab Interactable',
        xr_simulator: 'XR Simulator',
        xr_transition: 'XR Transition',
        xr_videoplayer: 'XR Video Player',
        gaze_pointer_interactor: 'Gaze Pointer Interactor',

        convert_main_camera_to_ar_camera: 'Convert Camera To AR Camera',
        ar_camera: 'AR Camera',
        plane_tracking: 'Plane Tracking',
        world_meshing: 'Meshing',
        image_tracking: 'Image Tracking',
        face_tracking: 'Face Tracking',
        screen_touch_interactor: 'Screen Touch Interactor',

        button: 'Button',
        editBox: 'EditBox',
        layout: 'Layout',
        pageView: 'PageView',
        progressBar: 'ProgressBar',
        richText: 'RichText',
        scrollView: 'ScrollView',
        slider: 'Slider',
        toggle: 'Toggle',
        toggleGroup: 'ToggleGroup',
        videoPlayer: 'VideoPlayer',
        webView: 'WebView',
        sprite: 'Sprite',
        label: 'Label',
    },
    ar: {
        add_factor: 'Add Factor',
        add_action: 'Add Action',
        reset_prop: 'Reset',
        remove_prop: 'Remove',
        add_landmark: 'Add Landmark',
        add_blendShape: 'Add Blend Shape',

        factors: {
            plane_direction: 'Plane Direction',
            plane_size: 'Plane Size',
            plane_semantic: 'Plane Semantic',
            image_source: 'Image Source',
            face: 'Face Tracking Content',
        },
        actions: {
            display_children: 'Display Children',
            surface_overlay: 'Surface Overlay',
            track_event: 'Track Event',
            alignment: 'Alignment',
            adaptive_scale: 'Adaptive Scale',
            face_landmark: 'Face LandMark',
            face_blend_shapes: 'Face BlendShapes',
            face_expression_events: 'Face Expression Events',
        },
    },
    hmd_ctrl: {
        perEyeCamera: 'Whether to open separate left and right eye nodes',
        syncWithMainCamera: 'Left and right eye nodes set whether to synchronize the main camera',
        IPDOffset: 'Whether to open to set Interpupillary distance',
        offsetValue: 'Value of interpupillary distance',
    },
    pose_tracker: {
        trackingSource: 'Specify the physical device to trace',
        trackingType: 'Device tracking mode, effective tracking variable',
    },
    target_eye: {
        targetEye: 'Target camera for rendering',
    },
    tracking_origin: {
        offsetObject: 'The node which need to offset',
        trackingOriginMode: 'Tracing migration mode',
        yOffsetValue: 'The offsetObject offset in the Y axis',
    },
    xr_controller: {
        inputDevice: 'Binding of physical input devices',
        selectActionLeft: 'Select state input key bindings (left)',
        activateActionLeft: 'Active input key bindings (left)',
        UIPressActionLeft: 'UiPress key bindings (left)',
        selectActionRight: 'Select state input key bindings (right)',
        activateActionRight: 'Active input key bindings (right)',
        UIPressActionRight: 'UiPress key bindings (right)',
        axisToPressThreshold: 'Minimum threshold for triggering behavior',
        model: 'Bind visual model of Controller',
    },
    xr_interactive_simulator: {
        xrAgent: 'Bind XR Agent. The default bind is the first XR Agent that is iterated over the current scene',        
        deviceIp: 'Enter the IP address of XR Device',
        previewType: 'Select Preview type',
        connectType: 'Select Remote Connection type',
    },
    interactable_events: {
        hoverEnterEvents: 'Hover start event',
        hoverStayEvents: 'Hover stay event',
        hoverExitEvents: 'Hover end event',
        selectEnterEvents: 'Select start event',
        selectStayEvents: 'Select stay event',
        selectExitEvents: 'Select end event',
        activeEnterEvents: 'Activation start event',
        activeStayEvents: 'Activation stay event',
        activeExitEvents: 'Activation end event',
    },
    interactor_events: {
        audioEvents: 'Audio trigger event',
        hapticEvents: 'Tactile triggering event',
        interactorEvents: 'Interaction events',
        audio_events: {
            onSelectEntered: 'Whether to enable the trigger audio that selects the start event',
            onSelectEnteredAudioClip: 'Select the trigger audio for the start event',
            onSelectStay: 'Whether to enable the trigger audio that selects the stay event',
            onSelectStayAudioClip: 'Select the trigger audio for the stay event',
            onSelectExited: 'Whether to enable the trigger audio for the select end event',
            onSelectExitedAudioClip: 'Select the trigger audio that ends the event',
            onHoverEntered: 'Whether to enable the trigger audio for the hover start event',
            onHoverEnteredAudioClip: 'Trigger audio for the hover start event',
            onHoverStay: 'Whether to enable the trigger audio for the hover stay event',
            onHoverStayAudioClip: 'Trigger audio for the hover stay event',
            onHoverExited: 'Whether to enable the trigger audio for the hover end event',
            onHoverExitedAudioClip: 'Trigger audio for the hover end event',
        },
        haptic_events: {
            onSelectEntered: 'Play haptics when the Select state is entered.',
            onSelectEnteredHaptic: 'Haptics intensity to play when the Select state is entered.',
            onSelectEnteredDuration: 'Haptics duration (in seconds) to play when the Select state is entered.',
            onSelectStay: 'Play haptics when the Select state is staying.',
            onSelectStayHaptic: 'Haptics intensity to play when the Select state is staying.',
            onSelectStayDuration: 'Haptics duration (in seconds) to play when the Select state is staying.',
            onSelectExited: 'Play haptics when the Select state is exited.',
            onSelectExitedHaptic: 'Haptics intensity to play when the Select state is exited without being canceled.',
            onSelectExitedDuration: 'Haptics duration (in seconds) to play when the Select state is exited without being canceled.',
            onHoverEntered: 'Play haptics when the Hover State is entered.',
            onHoverEnteredHaptic: 'Haptics intensity to play when the Hover state is entered.',
            onHoverEnteredDuration: 'Haptics duration (in seconds) to play when the Hover state is entered.',
            onHoverStay: 'Play haptics when the Hover state is staying.',
            onHoverStayHaptic: 'Haptics intensity to play when the Hover state is staying.',
            onHoverStayDuration: 'Haptics duration (in seconds) to play when the Hover state is staying.',
            onHoverExited: 'Play haptics when the Hover state is exited.',
            onHoverExitedHaptic: 'Haptics intensity to play when the Hover state is exited without being canceled.',
            onHoverExitedDuration: 'Haptics duration (in seconds) to play when the Hover state is exited without being canceled.',
        },
        sub_interactor_events: {
            hoverEnterEvents: 'Hover start event',
            hoverStayEvents: 'Hover stay event',
            hoverExitEvents: 'Hover ends the event',
            selectEnterEvents: 'Select start event',
            selectStayEvents: 'Select stay event',
            selectExitEvents: 'Select end event',
        },
    },
    xr_interactor: {
        interactionLayerMask: 'The layer can be interacted with.',
        attachTransform: 'Instead of the final position of the captured object, if empty, use the position of the current Interactor.',
        selectActionTrigger: 'Select the triggering mechanism for the behavior.',
    },
    ray_interactor: {
        forceGrab: 'When enabled, the captured object is attached to the AttachTransform, and when closed, the position attached to the interaction point is captured',
        rayOriginTransform: 'The position from which Ray is emitted, null defaults to the position of the current Interactor',
        maxRayDistance: 'The furthest distance a ray can be projected',
        reticle: 'Ray cursor',
        lineType: 'Line type of the ray cast.',
        referenceNode: 'The reference frame of the curve to define the ground plane and up. <br> If not set at startup it will try to find the XR Agent, <br> and if that does not exist it will use global up and origin by default.',
        velocity: 'Initial velocity of the projectile. Increase this value will make the curve reach further.',
        acceleration: 'Gravity of the projectile in the reference frame.',
        additionalGroundHeight: 'Additional height below ground level that the projectile will continue to. <br> Increasing this value will make the end point drop lower in height.',
        additionalFlightTime: '',
        endPointDistance: 'Increase this value distance will make the end of curve further from the start point.',
        endPointHeight: 'Decrease this value will make the end of the curve drop lower relative to the start point.',
        controlPointDistance: 'Increase this value will make the peak of the curve further from the start point.',
        controlPointHeight: 'Increase this value will make the peak of the curve higher relative to the start point.',
        sampleFrequency: 'The number of sample points used to approximate curved paths. <br> Larger values produce a better quality approximate at the cost of reduced performance due to the number of ray casts.',
        rayCastMask: 'Layer mask used for limiting ray cast targets.',
    },
    gaze_interactor: {
        gazeDefaultDistance: 'Gaze default distance',
        gazeTimerDuration: 'Gaze stay duration(unit:secons)',
        gazeReticleOuterRing: 'Gaze recticle outer ring sprite',
    },
    xr_interactable: {
        interactionLayerMask: '',
        rayReticle: 'When a ray touches an interaction, a reminder of the contact point display',
    },
    grab_interactable: {
        attachTransform: 'Use the position of this AttachTransform as the position at which the object is fetched, <br> or if it is empty use the position of the actual object (possibly a position of the object being fetched)',
        attachEaseInTime: 'The time consumed by the migration process of the captured object',
        grabTrigger: 'The event that triggers fetching',
        hideController: 'Whether to hide the XR Controller object model. Hide the XR Controller object model when enabled',
        throwOnDetach: 'When turned on, the object has physical properties that simulate the throwing behavior',
        throwSimulationMode: 'The calculation of the velocity of an object when thrown',
        throwSmoothingDuration: 'The time period used to calculate the average throwing speed',
        throwSmoothingCurve: 'The curve to use to weight thrown velocity smoothing (most recent frames to the right)',
        throwVelocityScale: 'The multiplier of speed inherited from the interactor during throwing',
        throwAngularVelocityScale: 'The multiplier of angular velocity inherited from the interactor during throwing',
        noPosition: 'Mask the movement signal of the interactivity.',
        noRotation: 'Mask the rotating signal of the interactivity.',
    },
    teleportable: {
        teleportableType: 'Teleport type, teleport point and teleport area',
        teleportAnchorNode: 'This is enabled when the transport type is transport point. <br> Defines the fixed location of the final transmission',
        teleportTrigger: 'The event that triggers the transport',
        teleporter: 'A transport object that can be transported to this point',
    },
    locomotion_base: {
        checker: 'Select to specify a Locomotion Checker, or if the user does not specify it, <br> the default binding traverses the current sence and obtains the first Locomotion Checker',
        inputDevice: 'Bind the input device that needs to read the signal',
        inputControl: 'Binding input controls',
    },
    continuous_mover: {
        moveSpeed: 'Speed of movement',
        forwardSource: 'An object specified as a forward direction',
    },
    continuous_turner: {
        turnSpeed: 'Speed of turning',
    },
    sharp_turner: {
        turnAngle: 'Fixed steering Angle each time',
        enableTurnAround: 'This allows XR Agent to rotate 180 degrees when the joystick is pressed',
        activationTimeout: 'The time required to wait while performing a continuous turn',
    },
    locomotion_checker: {
        xrAgent: 'Bind XR Agent. The default bind is the first XR Agent that is iterated over the current scene',
    },
    teleporter: {
        checker: 'Select to specify a Locomotion Checker, or if the user does not specify it, <br> the default binding traverses the current sence and obtains the first Locomotion Checker',
    },
    camera_following: {
        camera: 'Select the camera the UI wants to follow',
    },
    raycast_checker: {
        ignoreReversedUI: 'When enabled, it cannot interact with the reverse UI control',
    },
    xr_key: {
        key: 'The value of the key on the virtual keyboard',
    },
    xr_keyboard_input_field: {
        suspendTransform: 'XR keyboard floating position',
        xRKeyboard: 'Select the virtual keyboard object you want to reference (cc.xrkeyboard must be added)',
    },
    xr_keyboard: {
        disableUIInteractionWhenTyping: 'Whether to disable user interaction with other UI elements while typing. <br> Use this option to reduce the chance of the keyboard being shut down unexpectedly.',
        onCommitText: 'Submit a callback for input text events',
        onShowKeyboard: 'Show callbacks for XR keyboard events',
        onHideKeyboard: 'Hide callbacks for XR keyboard events',
    },
    xr_switch: {
        switch_latin: 'Key of latin keyboard',
        switch_symbol: 'Key of symbol keyboard',
        switch_math_symbol: 'Key of scientific calculation keyboard',
    },

    action: {
        display: {
            displayChildrenNode: 'Shows the child node object under the Tracking node',
            stopTracking: 'When the factors of the current node is queried, the tracking is turned off',
            resetWhenLoss: 'When enabled, the object\'s pose and scale will be reset if the data for it is lost',
        },
        alignment: {
            towards: 'The axis that will be aligned to the world up direction.  <br> If set to Local_Up,the data\'s pose rotation will be used directly.  <br> If set to World_Up, the local Y axis will always be aligned with the world Up direction.',
            faceToCamera: 'If checked, the z-axis of the subnode is toward the direction of the AR Camera',
            matchTrackingUpdate: 'When enabled movement of the matched data, the alignment and layout of subnode will be followed',
        },
        adaptive_scale: {
            maxScale: 'The Maximum value that child content scaled.',
            matchTrackingUpdate: 'Whether the child node\'s scale is constantly updated with the tracking.',
        },
        surface_overlay: {
            surfaceOffset: 'Offsets the created plane in local space. Offset in Y axis to clarify depth ordering.',
            replaceVisualizer: 'Use tracking node mesh renderer to replace Plane Visualizer.',
        },
        trackEvent: {
            onTrackSuccess: 'Called when a tracking node has been found.',
            onTrackRefresh: 'Called when a tracking node\'s data has updated.',
            onTrackLoss: 'Called when a tracking node has been lost.',
            onTrackTimeout: 'Called when no tracking node has been found in time.',
            timeout: {
                time: 'Sets how long this query should stay active before failing from lack of data.',
                event: 'Track failed events',
            },
        },
    },
    factor: {
        plane_direction: {
            directionType: 'Requires the object (a surface) to have the specified direction (horizontal, vertical, or other).',
        },
        plane_semantic: {
            semanticType: '',
        },
        plane_size: {
            useMinSize: 'If checked, Use minimum size to sets the plane\'s extents.',
            minSize: 'Sets the minimum size of the plane\'s extents.',
            useMaxSize: 'Use maximum size to sets the plane\'s extents.',
            maxSize: 'Sets the maximum size of the plane\'s extents.',
        },
        image_source: {
            imageSource: 'The list of images which will be detected and/or tracked in the physical environment.',

            image_set_item: {
                image: 'Represents a situation that depends on the existence of a specific image.',
                enablePhysicalSize: 'If checked, detected images can be matched up with the specify physical size.',
                imagePhysicalSize: 'The size of the image, in meters. <br> This can improve image detection, and might be required by some platforms.',
            },
        },
    },
    feature: {
        enable: 'If checked, the ar feature will be enabled at runtime.',
        tracking_List: 'Lists the tracking nodes in Hierarchy.',
        unsupportedEvent: 'When this feature is not supported, events are sent',
        plane: {
            direction_Type: 'Collects the plane orientations be used.',
            maxTrackingNumber: 'The maximum number of real-world plane tracked in one frame.',
            trackingVisualizer: 'Creates planes as you scan your environment to preview the scanned data has been gathered.',
            trackingQualityCondition: '',
            usePlaneShape: 'If checked, the planes will match the geometry of the scanned environment; <br> Unchecked will generate square planes.',
        },
        image: {
            maxTrackingNumber: 'The maximum number of real-world images tracked in one frame.',
        },
        world_mesh: {
            normals: 'If enabled, a normal is requested for each vertex.<br>This feature may not be implemented on all platforms. <br>See the platform-specific package documentation for your platform.',
        },
        face: {
            trackingMode: '面部追踪的方式',
            faceTrackingNode: '罗列当前编辑器中和Plane Tracking相关的能力节点',
            faceTrackingType: '三种模式Position、Rotation、Position And Rotation',
            maxTrackingNumber: '可追踪的面部最大值',
            faceTrackingOrderList: 'Face Tracking对象数组',
        },
    },
    tracking: {
        trackingType: 'The type of AR feature.',
        
        planeDirection: 'Represents a situation where a given plane must match a given set of alignments.',
        planeSize: 'Represents a situation where a given plane must have a size within a certain range.',
        planeSemantic: 'Represents a situation that depends on the existence or lack of a certain trait.',
        imageSource: 'Represents a situation that depends on the existence of specific image source.',

        surfaceOverlay: 'An action that overlay the plane visualization with the specified prefab.',
        display: 'Activates children if the parent Real World Object is tracked;<br> disables children otherwise.',
        trackEvent: 'Called during tracking node matching.',
        alignment: 'Sets the position of this node to the position of the found real-world object.',
        adaptiveScale: 'An action that scales child content by the bounds of its matching AR Object.',

        meshVisualizer: 'The prefab to be instantiated for each generated mesh.',

        faceModelPrefab: '',
        faceTrackingContent: '',
        faceLandMark: '',
        faceBlendShapes: '',
        faceExpressionEvents: '',

        cameraMgr: {
            autoFocus: 'Automatic camera focus',
            lightEstimate: 'If checked, AR device will access the most recently received basic light estimation information for the physical environment and apply to the scene\'s environment light.',
        },
        manager: {
            configuration: 'The global properties of AR feature',
        },
        session: {
            autoStartARSession: 'If checked, the AR Session is automatically started when the application is started.',
        },
    },

    screen_touch_gesture: {
        gesture: 'The gesture allows the user to manipulate virtual objects',
        selectAction: {
            doubleTapGap: 'Time threshold which be used to recognize the gesture of double tap.',
            holdTouchDuration: 'Time threshold which be used to recognize the gesture of hold touch.',
        },
        selectRotateAction: {
            dragDegree: 'The rate  which rotates the attached object with a drag gesture.',
            twistDegree: 'The rate which rotates the attached object with a twist gesture.',
        },
        selectScaleAction: {
            sensitivity: 'Sensitivity to movement being translated into scale.',
        },
        placeAction: {
            calculationMode: 'Mode which be used to calculate the hit point\'s position when place object on AR Surface',
            placement_Prefab: 'A prefab to place when a ray cast from a user touch hits a surface.',
        },
    },
    screen_touch_interactor: {
        selectAction: 'Configuration of the screen touch interactor\'s selection action.',
        placeAction: 'Configuration of the screen touch interactor\'s placement action.',
        selectScaleAction: 'Configuration of the screen touch interactor\'s movement action.',
        selectMoveAction: 'Configuration of the screen touch interactor\'s rotation action.',
        selectRotateAction: 'Configuration of the screen touch interactor\'s scale action.',
    },
    placeable: {
        preview_Placement_Prefab: 'A prefab to place before the placement action occured.',
        placementOffset: 'Offset the position of prefab which placed by interactor.',
        placementEvents: 'The placement action\'s callback, it will be triggered when certain event occurs.',
        placement_events: {
            placeEnterEvents: 'Trigger event when placement action start.',
            placeCancelEvents: 'Trigger event when placement action cancel.',
            placeFinishEvents: 'Trigger event when placement action finish.',
        },
    },
    selectable: {
        allowedActions: 'Allowed the action after this object be selected.',
        selectedVisualization: 'The visualization that will become active when the object is selected.',
        selectionEvents: 'The select action\'s callback, it will be triggered when certain event occurs.',
        select_events: {
            selectEnterEvents: 'Trigger event when select action starts.',
            selectExitEvents: 'Trigger event when select action exits.',
            selectCancelEvents: 'Trigger event when select action cancels.',
        },
    },

    document: {
        agree: 'agree',
        disagree: 'disagree',
    },
    builder: {
        asWebXR: {
            label: 'WebXR',
            description: 'Compatible with XR, add a Warning to inform the user at runtime if the browser does not support WebXR.',
        },
        enableAR: {
            label: 'Enable AR',
            description: 'If checked, the app will enable the AR capabilities of the device.',
        },
        rendering_scale: 'Adjust the rendering scale',
        msaa: 'Adjust the number of pixels that MultiSampling Anti-Aliasing takes part in the calculation',
        remote_preview: 'Whether to enable the Wi-Fi Directly project screen to preview',
    },
    videoplayer: {
        resourceType: 'The resource type of video player, <br>REMOTE for remote url and LOCAL for local file path.',
        remoteURL: 'The remote URL of video.',
        clip: 'The local video clip',
        playOnAwake: 'Whether the video start playing automatically after loaded?',
        volume: 'The volume of the video.(0.0 ~ 1.0)',
        mute: 'Mutes the VideoPlayer. Mute sets the volume = 0, Un-Mute restore the original volume.',
        playbackRate: 'The Video playback rate',
        loop: 'Whether the video should be played again at the end',
        keepAspectRatio: 'Whether keep the aspect ration of the original video.',
        videoPlayerEvent: 'The video player\'s callback, it will be triggered when certain event occurs, <br>like: playing, paused, stopped and completed.',
        videoShape: 'Video shape type : 2D/Pano 180/Pano 360',
        videoContent: 'Associated VideoContent with a MeshRenderer component as a video material rendering target',
        captionSourceType: 'The resource type of caption, <br>REMOTE for remote url and LOCAL for local file path.',
        captionRemoteURL: 'The remote URL of caption file',
        captionFile: 'The local caption file',
        videoPlayer: 'Specifies the video player UI to rely on',
    },
    XRVideoController: {
        videoPlayer: 'Bind the video player that you want to control.',
        hmdControl: 'Bind the XR HMD node.',
        leftHandController: 'Bind the left controller node.',
        rightHandController: 'Bind the right controller node.',
        playPause: 'UI of video\'s play/pause',
        progressBar: 'UI of progress bar',
        fastForward: 'UI Button of video\'s fast forward',
        rewind: 'UI Button of video\'s rewind',
        videoShapeUI: 'UI Button of video\'s shape',
        playerBackRateBar: 'UI Button of video\'s playing speed',
        volumeUI: 'UI Button of video\'s volume',
    },
};
